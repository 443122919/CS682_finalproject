# -*- coding: utf-8 -*-
"""tiny_imagenet_baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u4DRTKoTr1MSMisfc-doSUz2woyXgZ_h

# imports
"""

import random
import torch
import torchvision
from torchvision.models import resnet50
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from torchvision.datasets import VisionDataset
import os
import time
import matplotlib.pyplot as plt
from skimage import io, color
import numpy as np
import pandas as pd
import warnings
from torchvision.datasets import ImageFolder
from torchvision.datasets.folder import default_loader
from torchvision.datasets.utils import extract_archive, check_integrity, download_url, verify_str_arg

## Mount Google Drive Data (If using Google Colaboratory)
try:
    from google.colab import drive
    drive.mount('/content/gdrive')
except:
    print("Mounting Failed.")

data_path = '/content/gdrive/MyDrive/tiny-imagenet-200'
directory_path = '/content/gdrive/MyDrive/dl2021_final_pj'
# data_root = 'tiny-imagenet-200'

"""# DATA preparation

original size:

200 classes

train: 200*500

val: 10,000

test: 10,000

for train data, sample 50(10%)/5(1%) images from each class

val data are used to tune

test data to test

"""

!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip

!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200

# adopted from https://github.com/lvyilin/pytorch-fgvc-dataset/blob/master/tiny_imagenet.py
class TinyImageNet(VisionDataset):
    """`tiny-imageNet <http://cs231n.stanford.edu/tiny-imagenet-200.zip>`_ Dataset.
        Args:
            root (string): Root directory of the dataset.
            split (string, optional): The dataset split, supports ``train``, or ``val``.
            transform (callable, optional): A function/transform that  takes in an PIL image
               and returns a transformed version. E.g, ``transforms.RandomCrop``
            target_transform (callable, optional): A function/transform that takes in the
               target and transforms it.
            download (bool, optional): If true, downloads the dataset from the internet and
               puts it in root directory. If dataset is already downloaded, it is not
               downloaded again.
    """
    base_folder = 'tiny-imagenet-200/'
    url = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'
    filename = 'tiny-imagenet-200.zip'
    md5 = '90528d7ca1a48142e341f4ef8d21d0de'

    def __init__(self, root, split='train', transform=None, target_transform=None, download=False, percent=0.1):
        super(TinyImageNet, self).__init__(root, transform=transform, target_transform=target_transform)

        self.dataset_path = os.path.join(root, self.base_folder)
        self.loader = default_loader
        self.split = verify_str_arg(split, "split", ("train", "val",))
        self.percent = percent
        '''
        if self._check_integrity():
            print('Files already downloaded and verified.')
        elif download:
            self._download()
        else:
            raise RuntimeError(
                'Dataset not found. You can use download=True to download it.')
        '''
        if not os.path.isdir(self.dataset_path):
            print('Extracting...')
            extract_archive(os.path.join(root, self.filename))

        _, class_to_idx = find_classes(os.path.join(self.dataset_path, 'wnids.txt'))

        self.data = make_dataset(self.root, self.base_folder, self.split, class_to_idx, self.percent)

    def _download(self):
        print('Downloading...')
        download_url(self.url, root=self.root, filename=self.filename)
        print('Extracting...')
        extract_archive(os.path.join(self.root, self.filename))

    def _check_integrity(self):
        return check_integrity(os.path.join(self.root, self.filename), self.md5)

    def __getitem__(self, index):
        img_path, target = self.data[index]
        image = self.loader(img_path)

        if self.transform is not None:
            image = self.transform(image)
        if self.target_transform is not None:
            target = self.target_transform(target)

        return image, target

    def __len__(self):
        return len(self.data)


def find_classes(class_file):
    with open(class_file) as r:
        classes = list(map(lambda s: s.strip(), r.readlines()))

    classes.sort()
    class_to_idx = {classes[i]: i for i in range(len(classes))}

    return classes, class_to_idx


def make_dataset(root, base_folder, dirname, class_to_idx, percent=1):
    images = []
    dir_path = os.path.join(root, base_folder, dirname)

    if dirname == 'train':
        for fname in sorted(os.listdir(dir_path)):
            cls_fpath = os.path.join(dir_path, fname)
            if os.path.isdir(cls_fpath):
                cls_imgs_path = os.path.join(cls_fpath, 'images')
                image_names = os.listdir(cls_imgs_path)
                image_number = len(image_names)
                smaple_image_names = random.sample(image_names, int(image_number*percent))
                for imgname in sorted(smaple_image_names):
                    path = os.path.join(cls_imgs_path, imgname)
                    item = (path, class_to_idx[fname])
                    images.append(item)
    else:
        imgs_path = os.path.join(dir_path, 'images')
        imgs_annotations = os.path.join(dir_path, 'val_annotations.txt')

        with open(imgs_annotations) as r:
            data_info = map(lambda s: s.split('\t'), r.readlines())

        cls_map = {line_data[0]: line_data[1] for line_data in data_info}
        image_names = os.listdir(imgs_path)
        image_number = len(image_names)
        smaple_image_names = random.sample(image_names, int(image_number*percent))
        for imgname in smaple_image_names:
            path = os.path.join(imgs_path, imgname)
            item = (path, class_to_idx[cls_map[imgname]])
            images.append(item)

    return images

norm = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
# data augmentation to training data
train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(), norm])
test_transform = transforms.Compose([transforms.ToTensor(), norm])

train_dataset = TinyImageNet('.', split='train', download=False, transform=train_transform, percent = 0.1)
val_dataset = TinyImageNet('.', split='val', download=False, transform=test_transform)
# test_dataset = TinyImageNet('.', split='test', download=False, transform=test_transform)

batch_size=128
val_dataloader = DataLoader(val_dataset, batch_size=batch_size,  shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,  shuffle=True)

print(len(val_dataset))
print(len(train_dataset))

for image, label in test_dataset:
  print(image.shape)
  break

for image, label in train_dataloader:
  print(label)
  plt.imshow(image[0].permute(1, 2, 0))
  break

"""# model"""

## Helper
def initialize_model(use_resnet=True, pretrained=False, nclasses=10):
    """
    
    """
    ## Initialize Model
    if use_resnet:
        model = resnet50(pretrained=pretrained)
    else:
        model = vgg16(pretrained=True)
    ## Freeze Early Layers if Pretrained
    if pretrained:
        for parameter in model.parameters():
            parameter.requires_grad = False
    ## Update Output Layer
    if use_resnet:
        model.fc = torch.nn.Linear(2048, nclasses)
    else:
        model.classifier._modules['6'] = torch.nn.Linear(4096, nclasses)
    return model

"""# train function"""

def test_eval(verbose = 1):
    correct = 0
    total = 0
    loss_sum = 0
    for images, labels in val_dataloader:
        if torch.cuda.is_available():
            images, labels = images.cuda(), labels.cuda()
        # images = images.view(-1, 64*64)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted.float() == labels.float()).sum()

        loss_sum += loss_metric(outputs,labels).item()

    if verbose:
        print('Test accuracy: %f %%' % (100.0 * correct / total))
        print('Test loss: %f' % (loss_sum / total))

    return 100.0 * correct / total, loss_sum / total

def train(net,
          optimizer,
          loss_metric,
          scheduler,
          epochs = 10,
          load_model_path = None,
          save_model_name = 'resnet-tiny-10-baseline.pth',
          save_data_name = 'resnet-tiny-10-baseline_data.npz'
          ):

  if load_model_path:
    print('load model from drive')
    state_dict = torch.load(load_model_path)
    net.load_state_dict(state_dict)

  #define batch train loss recording array for later visualization/plotting:
  loss_batch_store = []
  train_perc_store = []
  test_perc_store = []
  test_adv_perc_store = []
  best_test_perc = 0
  print("Starting Training")
  #training loop:
  for epoch in range(epochs):
      time1 = time.time() #timekeeping

      net.train()
      total = 0
      correct = 0
      train_loss = 0
      for i, (x,y) in enumerate(train_dataloader):

          if torch.cuda.is_available():
            x = x.cuda()
            y = y.cuda()

          # x = x.view(x.shape[0],-1)
          #loss calculation and gradient update:

          if i > 0 or epoch > 0:
              optimizer.zero_grad()
          outputs = net.forward(x)
          _, predicted = torch.max(outputs.data, 1)
          total += y.size(0)
          correct += (predicted.float() == y.float()).sum()
          loss = loss_metric(outputs,y)
          train_loss += loss.item()
          loss.backward()

          if i > 0 or epoch > 0:
              loss_batch_store.append(loss.cpu().data.numpy().item())

          ##perform update:
          optimizer.step()

      print("Epoch",epoch+1,':')
      # train
      print('Train accuracy: %f %%' % (100.0 * correct / total))
      print('Train loss: %f' % (train_loss/total))
      train_perc = 100.0 * correct / total
      train_perc_store.append(train_perc.cpu().data.numpy().item())
      net.eval()
      # test
      test_perc, test_loss = test_eval()
      test_perc_store.append(test_perc.cpu().data.numpy().item())
      # save the model with highest acc on test set
      if test_perc > best_test_perc:
        best_test_perc = test_perc
        torch.save(net.state_dict(), os.path.join(directory_path, save_model_name ))
        print('new best test acc at', epoch+1)

      scheduler.step()
      time2 = time.time() #timekeeping
      print('Elapsed time for epoch:',time2 - time1,'s')
      print('ETA of completion:',(time2 - time1)*(epochs - epoch - 1)/60,'minutes')
      print()

      # save data
      save_filename = os.path.join(directory_path, save_data_name)
      np.savez(save_filename, train_perc_store=train_perc_store,  loss_batch_store = loss_batch_store, test_perc_store=test_perc_store, test_adv_perc_store=test_adv_perc_store)

  ## Plot batch-wise train loss curve:
  plt.plot(loss_batch_store, '-o', label = 'train_loss', color = 'blue')
  plt.xlabel('Minibatch Number')
  plt.ylabel('Sample-wise Loss At Last minibatch')
  plt.legend()
  plt.show()

"""# train start"""

## Get Model
net = initialize_model(use_resnet=True, pretrained=False, nclasses=200)
if torch.cuda.is_available:
  net = net.cuda()
optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)
train_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.975) 
loss_metric = torch.nn.CrossEntropyLoss()
train(net,
      optimizer,
      loss_metric,
      train_scheduler,
      epochs = 10,
      save_model_name = 'resnet-tiny-10-baseline.pth',
      save_data_name = 'resnet-tiny-10-baseline_data.npz'
      )

train(net,
      optimizer,
      loss_metric,
      train_scheduler,
      epochs = 100,
      save_model_name = 'resnet-tiny-10-baseline.pth',
      save_data_name = 'resnet-tiny-10-baseline_data_2.npz'
      )